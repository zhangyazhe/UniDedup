destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
Init container store successfully
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
append thread start
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: update 2 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 0
backup path: /hadoop15
number of files: 1
number of chunks: 1024 (4605 bytes on average)
number of unique chunks: 1024
total size(B): 4716477
stored data size(B): 4716477
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.080s, 56.53MB/s
chunk_time : 0.016s, 274.95MB/s
hash_time : 0.013s, 355.21MB/s
dedup_time : 0.001s, 8750.94MB/s
rewrite_time : 0.000s, 78911.98MB/s
filter_time : 0.009s, 515.65MB/s
write_time : 0.000s, 31675.94MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
append thread start
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 2 records.
CMA: update 4 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 1
backup path: /hadoop16
number of files: 1
number of chunks: 1024 (4989 bytes on average)
number of unique chunks: 1023
total size(B): 5109600
stored data size(B): 5102970
deduplication ratio: 0.0013, 1.0013
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.045s, 109.15MB/s
chunk_time : 0.017s, 289.40MB/s
hash_time : 0.015s, 331.17MB/s
dedup_time : 0.001s, 9299.42MB/s
rewrite_time : 0.000s, 101518.63MB/s
filter_time : 0.007s, 698.52MB/s
write_time : 0.000s, 38369.25MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 0 inherited sparse containers
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 4 records.
CMA: update 6 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 2
backup path: /hadoop17
number of files: 1
number of chunks: 1024 (4806 bytes on average)
number of unique chunks: 1023
total size(B): 4921921
stored data size(B): 4917369
deduplication ratio: 0.0009, 1.0009
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.034s, 136.64MB/s
chunk_time : 0.015s, 321.21MB/s
hash_time : 0.013s, 362.32MB/s
dedup_time : 0.002s, 2009.38MB/s
rewrite_time : 0.000s, 36107.00MB/s
filter_time : 0.034s, 137.57MB/s
write_time : 0.001s, 9313.31MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 1 inherited sparse containers
pkt size: 3
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 418 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 6 records.
CMA: update 7 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 3
backup path: /hadoop18
number of files: 1
number of chunks: 418 (6993 bytes on average)
number of unique chunks: 418
total size(B): 2923385
stored data size(B): 2923385
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.009s, 317.14MB/s
chunk_time : 0.008s, 356.97MB/s
hash_time : 0.007s, 384.39MB/s
dedup_time : 0.000s, 11616.49MB/s
rewrite_time : 0.000s, 121215.53MB/s
filter_time : 0.003s, 938.71MB/s
write_time : 0.000s, 24892.47MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 7 records.
CMA: update 8 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 4
backup path: /hadoop26
number of files: 1
number of chunks: 1024 (4955 bytes on average)
number of unique chunks: 669
total size(B): 5074912
stored data size(B): 3827775
deduplication ratio: 0.2457, 1.3258
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.078s, 62.13MB/s
chunk_time : 0.016s, 303.93MB/s
hash_time : 0.017s, 282.35MB/s
dedup_time : 0.001s, 4129.53MB/s
rewrite_time : 0.000s, 63681.75MB/s
filter_time : 0.012s, 408.63MB/s
write_time : 0.000s, 32923.90MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
==== backup begin ====
Read 1 inherited sparse containers
pkt size: 5
append thread start
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 0 of them are inherited
CMA: read 8 records.
CMA: update 10 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 5
backup path: /hadoop27
number of files: 1
number of chunks: 1024 (4600 bytes on average)
number of unique chunks: 817
total size(B): 4711348
stored data size(B): 4269454
deduplication ratio: 0.0938, 1.1035
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.074s, 60.87MB/s
chunk_time : 0.014s, 317.31MB/s
hash_time : 0.011s, 405.29MB/s
dedup_time : 0.001s, 5182.34MB/s
rewrite_time : 0.000s, 41221.02MB/s
filter_time : 0.021s, 213.06MB/s
write_time : 0.000s, 20058.44MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 3 inherited sparse containers
pkt size: 4
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 674 chunks on average
rewrite phase stops successfully!
Record 2 sparse containers, and 1 of them are inherited
CMA: read 10 records.
CMA: update 11 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 6
backup path: /hadoop28
number of files: 1
number of chunks: 674 (6222 bytes on average)
number of unique chunks: 539
total size(B): 4193873
stored data size(B): 3749697
deduplication ratio: 0.1059, 1.1185
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.031s, 130.23MB/s
chunk_time : 0.024s, 169.09MB/s
hash_time : 0.014s, 286.32MB/s
dedup_time : 0.001s, 2693.33MB/s
rewrite_time : 0.000s, 76915.17MB/s
filter_time : 0.013s, 309.66MB/s
write_time : 0.000s, 44939.20MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
==== backup begin ====
Read 2 inherited sparse containers
append thread start
pkt size: 5
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 11 records.
CMA: update 12 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 7
backup path: /hadoop35
number of files: 1
number of chunks: 1024 (4670 bytes on average)
number of unique chunks: 690
total size(B): 4783039
stored data size(B): 3554030
deduplication ratio: 0.2570, 1.3458
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.070s, 65.63MB/s
chunk_time : 0.016s, 277.49MB/s
hash_time : 0.012s, 379.77MB/s
dedup_time : 0.001s, 5515.67MB/s
rewrite_time : 0.000s, 84471.51MB/s
filter_time : 0.008s, 549.04MB/s
write_time : 0.000s, 10682.58MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
append thread start
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 12 records.
CMA: update 13 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 8
backup path: /hadoop36
number of files: 1
number of chunks: 1024 (4916 bytes on average)
number of unique chunks: 611
total size(B): 5034553
stored data size(B): 3586436
deduplication ratio: 0.2876, 1.4038
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.060s, 79.72MB/s
chunk_time : 0.021s, 231.91MB/s
hash_time : 0.015s, 327.74MB/s
dedup_time : 0.002s, 2844.39MB/s
rewrite_time : 0.000s, 73866.52MB/s
filter_time : 0.009s, 531.59MB/s
write_time : 0.000s, 12003.31MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 1 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 0 of them are inherited
CMA: read 13 records.
CMA: update 15 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 9
backup path: /hadoop37
number of files: 1
number of chunks: 1024 (4733 bytes on average)
number of unique chunks: 819
total size(B): 4847526
stored data size(B): 4443367
deduplication ratio: 0.0834, 1.0910
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.027s, 172.57MB/s
chunk_time : 0.017s, 271.06MB/s
hash_time : 0.012s, 380.46MB/s
dedup_time : 0.001s, 3968.21MB/s
rewrite_time : 0.000s, 72233.77MB/s
filter_time : 0.010s, 485.20MB/s
write_time : 0.000s, 28017.95MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 3 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 745 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 2 of them are inherited
CMA: read 15 records.
CMA: update 16 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 10
backup path: /hadoop38
number of files: 1
number of chunks: 745 (6137 bytes on average)
number of unique chunks: 580
total size(B): 4572661
stored data size(B): 4056985
deduplication ratio: 0.1128, 1.1271
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.035s, 124.61MB/s
chunk_time : 0.014s, 318.31MB/s
hash_time : 0.012s, 371.39MB/s
dedup_time : 0.001s, 4949.86MB/s
rewrite_time : 0.000s, 140671.91MB/s
filter_time : 0.004s, 1240.28MB/s
write_time : 0.000s, 62297.56MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 16 records.
CMA: update 17 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 11
backup path: /hadoop45
number of files: 1
number of chunks: 1024 (4599 bytes on average)
number of unique chunks: 670
total size(B): 4709677
stored data size(B): 3239313
deduplication ratio: 0.3122, 1.4539
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.081s, 55.65MB/s
chunk_time : 0.013s, 335.41MB/s
hash_time : 0.013s, 338.29MB/s
dedup_time : 0.001s, 4447.03MB/s
rewrite_time : 0.000s, 86374.96MB/s
filter_time : 0.004s, 1164.51MB/s
write_time : 0.000s, 38388.87MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 17 records.
CMA: update 18 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 12
backup path: /hadoop46
number of files: 1
number of chunks: 1024 (4355 bytes on average)
number of unique chunks: 707
total size(B): 4460316
stored data size(B): 3278290
deduplication ratio: 0.2650, 1.3606
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.024s, 174.75MB/s
chunk_time : 0.017s, 248.94MB/s
hash_time : 0.012s, 365.25MB/s
dedup_time : 0.002s, 2762.14MB/s
rewrite_time : 0.000s, 57482.28MB/s
filter_time : 0.010s, 411.10MB/s
write_time : 0.001s, 7582.33MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 1 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 1 of them are inherited
CMA: read 18 records.
CMA: update 20 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 13
backup path: /hadoop47
number of files: 1
number of chunks: 1024 (4922 bytes on average)
number of unique chunks: 892
total size(B): 5040745
stored data size(B): 4678477
deduplication ratio: 0.0719, 1.0774
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.028s, 168.92MB/s
chunk_time : 0.016s, 307.09MB/s
hash_time : 0.014s, 352.02MB/s
dedup_time : 0.002s, 2156.68MB/s
rewrite_time : 0.000s, 15117.07MB/s
filter_time : 0.023s, 205.23MB/s
write_time : 0.000s, 29858.57MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 2 of them are inherited
CMA: read 20 records.
CMA: update 21 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 14
backup path: /hadoop48
number of files: 1
number of chunks: 1024 (4640 bytes on average)
number of unique chunks: 780
total size(B): 4751910
stored data size(B): 4089722
deduplication ratio: 0.1394, 1.1619
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.014s, 334.18MB/s
chunk_time : 0.022s, 207.47MB/s
hash_time : 0.014s, 319.00MB/s
dedup_time : 0.001s, 3412.48MB/s
rewrite_time : 0.000s, 102994.88MB/s
filter_time : 0.006s, 727.29MB/s
write_time : 0.000s, 65677.89MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 5
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 21 records.
CMA: update 23 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 15
backup path: /hadoop52
number of files: 1
number of chunks: 1024 (4878 bytes on average)
number of unique chunks: 1024
total size(B): 4995445
stored data size(B): 4995445
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.041s, 115.80MB/s
chunk_time : 0.021s, 222.65MB/s
hash_time : 0.016s, 295.17MB/s
dedup_time : 0.001s, 9196.96MB/s
rewrite_time : 0.000s, 62684.57MB/s
filter_time : 0.010s, 495.32MB/s
write_time : 0.000s, 14306.39MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
append thread start
Init container store successfully
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 0 of them are inherited
CMA: read 23 records.
CMA: update 24 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 16
backup path: /hadoop56
number of files: 1
number of chunks: 1024 (4594 bytes on average)
number of unique chunks: 638
total size(B): 4704966
stored data size(B): 3346640
deduplication ratio: 0.2887, 1.4059
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.048s, 93.62MB/s
chunk_time : 0.028s, 158.52MB/s
hash_time : 0.012s, 375.48MB/s
dedup_time : 0.002s, 2351.68MB/s
rewrite_time : 0.000s, 95468.20MB/s
filter_time : 0.004s, 1077.31MB/s
write_time : 0.000s, 41934.63MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 5 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 3 of them are inherited
CMA: read 24 records.
CMA: update 25 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 17
backup path: /hadoop57
number of files: 1
number of chunks: 1024 (4689 bytes on average)
number of unique chunks: 718
total size(B): 4802221
stored data size(B): 3580716
deduplication ratio: 0.2544, 1.3411
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.015s, 302.89MB/s
chunk_time : 0.028s, 162.25MB/s
hash_time : 0.017s, 266.71MB/s
dedup_time : 0.001s, 3081.93MB/s
rewrite_time : 0.000s, 111701.34MB/s
filter_time : 0.004s, 1266.53MB/s
write_time : 0.000s, 72694.52MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 5 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 7 sparse containers, and 2 of them are inherited
CMA: read 25 records.
CMA: update 27 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 18
backup path: /hadoop58
number of files: 1
number of chunks: 1024 (4664 bytes on average)
number of unique chunks: 884
total size(B): 4776009
stored data size(B): 4532529
deduplication ratio: 0.0510, 1.0537
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.015s, 310.04MB/s
chunk_time : 0.013s, 351.80MB/s
hash_time : 0.015s, 296.51MB/s
dedup_time : 0.002s, 2901.12MB/s
rewrite_time : 0.000s, 74668.15MB/s
filter_time : 0.014s, 319.32MB/s
write_time : 0.001s, 7229.77MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 7 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 747 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 0 of them are inherited
CMA: read 27 records.
CMA: update 28 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 19
backup path: /hadoop59
number of files: 1
number of chunks: 747 (6044 bytes on average)
number of unique chunks: 620
total size(B): 4515202
stored data size(B): 4106985
deduplication ratio: 0.0904, 1.0994
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.030s, 143.08MB/s
chunk_time : 0.019s, 231.16MB/s
hash_time : 0.033s, 129.59MB/s
dedup_time : 0.001s, 5296.47MB/s
rewrite_time : 0.000s, 87878.21MB/s
filter_time : 0.011s, 377.29MB/s
write_time : 0.000s, 43939.10MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
==== backup begin ====
Read 3 inherited sparse containers
append thread start
pkt size: 5
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 28 records.
CMA: update 29 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 20
backup path: /hadoop62
number of files: 1
number of chunks: 1024 (4795 bytes on average)
number of unique chunks: 746
total size(B): 4910709
stored data size(B): 4096828
deduplication ratio: 0.1657, 1.1987
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.025s, 185.35MB/s
chunk_time : 0.029s, 164.26MB/s
hash_time : 0.020s, 228.90MB/s
dedup_time : 0.001s, 5490.29MB/s
rewrite_time : 0.000s, 123242.55MB/s
filter_time : 0.005s, 1005.63MB/s
write_time : 0.000s, 9557.59MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 1 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 0 of them are inherited
CMA: read 29 records.
CMA: update 30 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 21
backup path: /hadoop66
number of files: 1
number of chunks: 1024 (4538 bytes on average)
number of unique chunks: 575
total size(B): 4647277
stored data size(B): 3052245
deduplication ratio: 0.3432, 1.5226
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.037s, 120.29MB/s
chunk_time : 0.025s, 179.29MB/s
hash_time : 0.016s, 285.75MB/s
dedup_time : 0.002s, 2751.08MB/s
rewrite_time : 0.000s, 79142.66MB/s
filter_time : 0.008s, 558.26MB/s
write_time : 0.000s, 57558.30MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 5 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 6 sparse containers, and 3 of them are inherited
CMA: read 30 records.
CMA: update 31 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 22
backup path: /hadoop67
number of files: 1
number of chunks: 1024 (4723 bytes on average)
number of unique chunks: 706
total size(B): 4837185
stored data size(B): 3621264
deduplication ratio: 0.2514, 1.3358
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.013s, 358.24MB/s
chunk_time : 0.014s, 337.26MB/s
hash_time : 0.016s, 285.18MB/s
dedup_time : 0.003s, 1583.08MB/s
rewrite_time : 0.000s, 121397.34MB/s
filter_time : 0.004s, 1267.68MB/s
write_time : 0.000s, 76884.98MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 6 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 10 sparse containers, and 2 of them are inherited
CMA: read 31 records.
CMA: update 33 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 23
backup path: /hadoop68
number of files: 1
number of chunks: 1024 (4687 bytes on average)
number of unique chunks: 760
total size(B): 4800245
stored data size(B): 4220795
deduplication ratio: 0.1207, 1.1373
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.012s, 393.02MB/s
chunk_time : 0.015s, 311.80MB/s
hash_time : 0.013s, 344.33MB/s
dedup_time : 0.005s, 964.98MB/s
rewrite_time : 0.000s, 101730.45MB/s
filter_time : 0.007s, 652.21MB/s
write_time : 0.000s, 30723.96MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 10 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 866 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 1 of them are inherited
CMA: read 33 records.
CMA: update 34 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 24
backup path: /hadoop69
number of files: 1
number of chunks: 866 (5312 bytes on average)
number of unique chunks: 722
total size(B): 4600836
stored data size(B): 4116009
deduplication ratio: 0.1054, 1.1178
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.032s, 135.93MB/s
chunk_time : 0.020s, 220.73MB/s
hash_time : 0.013s, 344.00MB/s
dedup_time : 0.003s, 1554.82MB/s
rewrite_time : 0.000s, 23093.15MB/s
filter_time : 0.004s, 1010.06MB/s
write_time : 0.000s, 68557.80MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 5 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 0 of them are inherited
CMA: read 34 records.
CMA: update 35 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 25
backup path: /hadoop76
number of files: 1
number of chunks: 1024 (4729 bytes on average)
number of unique chunks: 777
total size(B): 4842705
stored data size(B): 3860539
deduplication ratio: 0.2028, 1.2544
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.076s, 60.92MB/s
chunk_time : 0.020s, 232.71MB/s
hash_time : 0.017s, 274.17MB/s
dedup_time : 0.001s, 4240.92MB/s
rewrite_time : 0.000s, 40511.96MB/s
filter_time : 0.025s, 185.07MB/s
write_time : 0.000s, 75710.88MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 4 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 6 sparse containers, and 3 of them are inherited
CMA: read 35 records.
CMA: update 36 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 26
backup path: /hadoop77
number of files: 1
number of chunks: 1024 (4829 bytes on average)
number of unique chunks: 775
total size(B): 4945190
stored data size(B): 4027659
deduplication ratio: 0.1855, 1.2278
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.030s, 158.19MB/s
chunk_time : 0.017s, 272.48MB/s
hash_time : 0.014s, 331.70MB/s
dedup_time : 0.002s, 2024.95MB/s
rewrite_time : 0.000s, 112288.11MB/s
filter_time : 0.005s, 1025.02MB/s
write_time : 0.000s, 57513.42MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 6 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 1 of them are inherited
CMA: read 36 records.
CMA: update 38 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 27
backup path: /hadoop78
number of files: 1
number of chunks: 1024 (4641 bytes on average)
number of unique chunks: 1001
total size(B): 4752402
stored data size(B): 4726932
deduplication ratio: 0.0054, 1.0054
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.011s, 395.69MB/s
chunk_time : 0.021s, 218.37MB/s
hash_time : 0.014s, 325.22MB/s
dedup_time : 0.001s, 3588.47MB/s
rewrite_time : 0.000s, 100716.53MB/s
filter_time : 0.007s, 653.34MB/s
write_time : 0.000s, 33082.07MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 5 inherited sparse containers
pkt size: 6
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 1 of them are inherited
CMA: read 38 records.
CMA: update 40 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 28
backup path: /hadoop79
number of files: 1
number of chunks: 1024 (5785 bytes on average)
number of unique chunks: 863
total size(B): 5924679
stored data size(B): 5457781
deduplication ratio: 0.0788, 1.0855
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.027s, 206.41MB/s
chunk_time : 0.020s, 289.74MB/s
hash_time : 0.023s, 248.46MB/s
dedup_time : 0.001s, 4012.94MB/s
rewrite_time : 0.000s, 102731.17MB/s
filter_time : 0.009s, 600.70MB/s
write_time : 0.000s, 13079.20MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 5 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 2 sparse containers, and 1 of them are inherited
CMA: read 40 records.
CMA: update 42 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 29
backup path: /hadoop82
number of files: 1
number of chunks: 1024 (4869 bytes on average)
number of unique chunks: 896
total size(B): 4986818
stored data size(B): 4609397
deduplication ratio: 0.0757, 1.0819
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.145s, 32.91MB/s
chunk_time : 0.019s, 244.04MB/s
hash_time : 0.012s, 399.58MB/s
dedup_time : 0.001s, 3866.50MB/s
rewrite_time : 0.000s, 38046.40MB/s
filter_time : 0.029s, 165.32MB/s
write_time : 0.001s, 8678.47MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 2 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 6 sparse containers, and 2 of them are inherited
CMA: read 42 records.
CMA: update 43 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 30
backup path: /hadoop87
number of files: 1
number of chunks: 1024 (4593 bytes on average)
number of unique chunks: 682
total size(B): 4703766
stored data size(B): 3446816
deduplication ratio: 0.2672, 1.3647
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.039s, 114.29MB/s
chunk_time : 0.026s, 172.49MB/s
hash_time : 0.014s, 312.08MB/s
dedup_time : 0.002s, 2483.87MB/s
rewrite_time : 0.000s, 109411.24MB/s
filter_time : 0.003s, 1372.24MB/s
write_time : 0.000s, 72352.59MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 6 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 2 of them are inherited
CMA: read 43 records.
CMA: update 45 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 31
backup path: /hadoop88
number of files: 1
number of chunks: 1024 (4744 bytes on average)
number of unique chunks: 863
total size(B): 4858619
stored data size(B): 4373681
deduplication ratio: 0.0998, 1.1109
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.016s, 285.90MB/s
chunk_time : 0.018s, 259.44MB/s
hash_time : 0.012s, 393.34MB/s
dedup_time : 0.002s, 2362.85MB/s
rewrite_time : 0.000s, 118808.72MB/s
filter_time : 0.005s, 910.86MB/s
write_time : 0.000s, 40291.65MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 5 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 0 of them are inherited
CMA: read 45 records.
CMA: update 46 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 32
backup path: /hadoop96
number of files: 1
number of chunks: 1024 (4624 bytes on average)
number of unique chunks: 746
total size(B): 4735090
stored data size(B): 3634658
deduplication ratio: 0.2324, 1.3028
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.079s, 56.83MB/s
chunk_time : 0.026s, 174.76MB/s
hash_time : 0.013s, 340.86MB/s
dedup_time : 0.002s, 2966.97MB/s
rewrite_time : 0.000s, 51315.16MB/s
filter_time : 0.015s, 301.23MB/s
write_time : 0.000s, 74028.42MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 8 sparse containers, and 3 of them are inherited
CMA: read 46 records.
CMA: update 47 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 33
backup path: /hadoop97
number of files: 1
number of chunks: 1024 (4693 bytes on average)
number of unique chunks: 627
total size(B): 4805882
stored data size(B): 3413753
deduplication ratio: 0.2897, 1.4078
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.015s, 313.23MB/s
chunk_time : 0.033s, 137.28MB/s
hash_time : 0.012s, 387.62MB/s
dedup_time : 0.002s, 2356.42MB/s
rewrite_time : 0.000s, 97515.88MB/s
filter_time : 0.004s, 1173.09MB/s
write_time : 0.001s, 8394.22MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 8 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 9 sparse containers, and 2 of them are inherited
CMA: read 47 records.
CMA: update 48 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 34
backup path: /hadoop98
number of files: 1
number of chunks: 1024 (4763 bytes on average)
number of unique chunks: 739
total size(B): 4877805
stored data size(B): 4106029
deduplication ratio: 0.1582, 1.1880
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.024s, 194.84MB/s
chunk_time : 0.017s, 277.47MB/s
hash_time : 0.014s, 329.12MB/s
dedup_time : 0.003s, 1438.86MB/s
rewrite_time : 0.000s, 101126.90MB/s
filter_time : 0.005s, 970.75MB/s
write_time : 0.000s, 75029.63MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 9 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 1 of them are inherited
CMA: read 48 records.
CMA: update 50 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 35
backup path: /hadoop102
number of files: 1
number of chunks: 1024 (4764 bytes on average)
number of unique chunks: 836
total size(B): 4879010
stored data size(B): 4398949
deduplication ratio: 0.0984, 1.1091
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.103s, 45.23MB/s
chunk_time : 0.019s, 240.06MB/s
hash_time : 0.015s, 305.07MB/s
dedup_time : 0.002s, 3075.34MB/s
rewrite_time : 0.000s, 58898.56MB/s
filter_time : 0.014s, 328.53MB/s
write_time : 0.000s, 30411.68MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 3 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 6 sparse containers, and 2 of them are inherited
CMA: read 50 records.
CMA: update 51 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 36
backup path: /hadoop107
number of files: 1
number of chunks: 1024 (4310 bytes on average)
number of unique chunks: 579
total size(B): 4413829
stored data size(B): 2797334
deduplication ratio: 0.3662, 1.5779
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.027s, 154.08MB/s
chunk_time : 0.013s, 328.70MB/s
hash_time : 0.015s, 281.19MB/s
dedup_time : 0.002s, 2085.90MB/s
rewrite_time : 0.000s, 91507.73MB/s
filter_time : 0.006s, 709.24MB/s
write_time : 0.000s, 15824.64MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 6 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 10 sparse containers, and 2 of them are inherited
CMA: read 51 records.
CMA: update 53 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 37
backup path: /hadoop108
number of files: 1
number of chunks: 1024 (4861 bytes on average)
number of unique chunks: 735
total size(B): 4978211
stored data size(B): 4175632
deduplication ratio: 0.1612, 1.1922
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.013s, 351.99MB/s
chunk_time : 0.018s, 268.38MB/s
hash_time : 0.016s, 291.85MB/s
dedup_time : 0.004s, 1344.17MB/s
rewrite_time : 0.000s, 65035.51MB/s
filter_time : 0.012s, 397.85MB/s
write_time : 0.000s, 41645.54MB/s
1
2
