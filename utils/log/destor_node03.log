destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
Init container store successfully
Init index module successfully
==== backup begin ====
append thread start
Read 0 inherited sparse containers
pkt size: 5
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: update 2 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 0
backup path: /hadoop10
number of files: 1
number of chunks: 1024 (4879 bytes on average)
number of unique chunks: 1024
total size(B): 4996940
stored data size(B): 4996940
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.153s, 31.05MB/s
chunk_time : 0.016s, 297.38MB/s
hash_time : 0.013s, 378.60MB/s
dedup_time : 0.002s, 2907.54MB/s
rewrite_time : 0.000s, 59568.17MB/s
filter_time : 0.013s, 368.81MB/s
write_time : 0.001s, 8160.02MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 2 records.
CMA: update 4 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 1
backup path: /hadoop11
number of files: 1
number of chunks: 1024 (4519 bytes on average)
number of unique chunks: 1021
total size(B): 4627506
stored data size(B): 4618398
deduplication ratio: 0.0020, 1.0020
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.079s, 56.02MB/s
chunk_time : 0.022s, 204.73MB/s
hash_time : 0.015s, 296.08MB/s
dedup_time : 0.000s, 9155.88MB/s
rewrite_time : 0.000s, 88262.67MB/s
filter_time : 0.014s, 308.59MB/s
write_time : 0.000s, 37399.44MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 4 records.
CMA: update 6 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 2
backup path: /hadoop12
number of files: 1
number of chunks: 1024 (4718 bytes on average)
number of unique chunks: 1024
total size(B): 4831720
stored data size(B): 4831720
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.084s, 55.15MB/s
chunk_time : 0.017s, 273.51MB/s
hash_time : 0.030s, 153.61MB/s
dedup_time : 0.002s, 2679.00MB/s
rewrite_time : 0.000s, 79446.33MB/s
filter_time : 0.022s, 214.00MB/s
write_time : 0.002s, 2733.03MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 0 inherited sparse containers
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 6 records.
CMA: update 8 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 3
backup path: /hadoop13
number of files: 1
number of chunks: 1024 (4551 bytes on average)
number of unique chunks: 1024
total size(B): 4660722
stored data size(B): 4660722
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.041s, 109.74MB/s
chunk_time : 0.017s, 266.67MB/s
hash_time : 0.027s, 164.17MB/s
dedup_time : 0.001s, 8402.29MB/s
rewrite_time : 0.000s, 116968.71MB/s
filter_time : 0.006s, 694.61MB/s
write_time : 0.002s, 2669.56MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
append thread start
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 8 records.
CMA: update 10 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 4
backup path: /hadoop14
number of files: 1
number of chunks: 1024 (4745 bytes on average)
number of unique chunks: 984
total size(B): 4859683
stored data size(B): 4697253
deduplication ratio: 0.0334, 1.0346
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.074s, 62.95MB/s
chunk_time : 0.016s, 289.97MB/s
hash_time : 0.025s, 182.51MB/s
dedup_time : 0.001s, 6454.81MB/s
rewrite_time : 0.000s, 96553.23MB/s
filter_time : 0.015s, 306.48MB/s
write_time : 0.001s, 3484.63MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 10 records.
CMA: update 11 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 5
backup path: /hadoop20
number of files: 1
number of chunks: 1024 (4804 bytes on average)
number of unique chunks: 288
total size(B): 4919818
stored data size(B): 1566972
deduplication ratio: 0.6815, 3.1397
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.074s, 63.79MB/s
chunk_time : 0.013s, 374.96MB/s
hash_time : 0.030s, 153.93MB/s
dedup_time : 0.001s, 3130.02MB/s
rewrite_time : 0.000s, 114436.68MB/s
filter_time : 0.002s, 1970.56MB/s
write_time : 0.000s, 104264.53MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 1 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 2 sparse containers, and 1 of them are inherited
CMA: read 11 records.
CMA: update 12 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 6
backup path: /hadoop21
number of files: 1
number of chunks: 1024 (4570 bytes on average)
number of unique chunks: 593
total size(B): 4680328
stored data size(B): 3251222
deduplication ratio: 0.3053, 1.4396
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.053s, 84.46MB/s
chunk_time : 0.019s, 240.21MB/s
hash_time : 0.025s, 177.06MB/s
dedup_time : 0.002s, 2278.46MB/s
rewrite_time : 0.000s, 106274.01MB/s
filter_time : 0.004s, 1234.72MB/s
write_time : 0.000s, 81154.70MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 2 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 1 of them are inherited
CMA: read 12 records.
CMA: update 14 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 7
backup path: /hadoop22
number of files: 1
number of chunks: 1024 (4772 bytes on average)
number of unique chunks: 819
total size(B): 4886557
stored data size(B): 4324717
deduplication ratio: 0.1150, 1.1299
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.098s, 47.74MB/s
chunk_time : 0.020s, 228.43MB/s
hash_time : 0.021s, 222.68MB/s
dedup_time : 0.001s, 5594.46MB/s
rewrite_time : 0.000s, 70608.85MB/s
filter_time : 0.012s, 379.06MB/s
write_time : 0.000s, 28590.09MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 3 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 1 of them are inherited
CMA: read 14 records.
CMA: update 15 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 8
backup path: /hadoop23
number of files: 1
number of chunks: 1024 (4390 bytes on average)
number of unique chunks: 569
total size(B): 4495422
stored data size(B): 2889443
deduplication ratio: 0.3572, 1.5558
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.080s, 53.40MB/s
chunk_time : 0.025s, 173.29MB/s
hash_time : 0.014s, 296.75MB/s
dedup_time : 0.001s, 5670.86MB/s
rewrite_time : 0.000s, 115869.42MB/s
filter_time : 0.003s, 1307.46MB/s
write_time : 0.000s, 38278.29MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 1 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 15 records.
CMA: update 16 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 9
backup path: /hadoop24
number of files: 1
number of chunks: 1024 (4607 bytes on average)
number of unique chunks: 571
total size(B): 4717801
stored data size(B): 2996435
deduplication ratio: 0.3649, 1.5745
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.034s, 133.91MB/s
chunk_time : 0.015s, 302.31MB/s
hash_time : 0.014s, 316.22MB/s
dedup_time : 0.001s, 3687.91MB/s
rewrite_time : 0.000s, 145136.96MB/s
filter_time : 0.003s, 1459.37MB/s
write_time : 0.000s, 77573.20MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 1 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 16 records.
CMA: update 18 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 10
backup path: /hadoop25
number of files: 1
number of chunks: 1024 (4638 bytes on average)
number of unique chunks: 951
total size(B): 4750280
stored data size(B): 4410065
deduplication ratio: 0.0716, 1.0771
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.065s, 69.71MB/s
chunk_time : 0.025s, 180.49MB/s
hash_time : 0.025s, 181.52MB/s
dedup_time : 0.001s, 5793.12MB/s
rewrite_time : 0.000s, 49782.64MB/s
filter_time : 0.022s, 208.44MB/s
write_time : 0.001s, 4525.69MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 1 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 2 sparse containers, and 0 of them are inherited
CMA: read 18 records.
CMA: update 19 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 11
backup path: /hadoop30
number of files: 1
number of chunks: 1024 (4821 bytes on average)
number of unique chunks: 257
total size(B): 4936977
stored data size(B): 1418642
deduplication ratio: 0.7126, 3.4801
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.164s, 28.73MB/s
chunk_time : 0.027s, 176.54MB/s
hash_time : 0.021s, 228.75MB/s
dedup_time : 0.002s, 3002.72MB/s
rewrite_time : 0.000s, 117706.70MB/s
filter_time : 0.002s, 2288.90MB/s
write_time : 0.000s, 82601.20MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 2 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 2 sparse containers, and 1 of them are inherited
CMA: read 19 records.
CMA: update 20 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 12
backup path: /hadoop31
number of files: 1
number of chunks: 1024 (4491 bytes on average)
number of unique chunks: 597
total size(B): 4599029
stored data size(B): 3175617
deduplication ratio: 0.3095, 1.4482
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.065s, 67.14MB/s
chunk_time : 0.015s, 291.39MB/s
hash_time : 0.017s, 253.04MB/s
dedup_time : 0.002s, 2643.75MB/s
rewrite_time : 0.000s, 99681.27MB/s
filter_time : 0.004s, 1065.07MB/s
write_time : 0.000s, 53487.51MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
append thread start
==== backup begin ====
Read 2 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 1 of them are inherited
CMA: read 20 records.
CMA: update 22 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 13
backup path: /hadoop32
number of files: 1
number of chunks: 1024 (4834 bytes on average)
number of unique chunks: 795
total size(B): 4950536
stored data size(B): 4330521
deduplication ratio: 0.1252, 1.1432
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.064s, 73.31MB/s
chunk_time : 0.036s, 132.61MB/s
hash_time : 0.016s, 295.94MB/s
dedup_time : 0.002s, 2900.00MB/s
rewrite_time : 0.001s, 8742.96MB/s
filter_time : 0.035s, 133.02MB/s
write_time : 0.000s, 24462.17MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 5 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 2 sparse containers, and 1 of them are inherited
CMA: read 22 records.
CMA: update 23 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 14
backup path: /hadoop33
number of files: 1
number of chunks: 1024 (4405 bytes on average)
number of unique chunks: 634
total size(B): 4511329
stored data size(B): 3206691
deduplication ratio: 0.2892, 1.4068
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.043s, 100.29MB/s
chunk_time : 0.020s, 214.55MB/s
hash_time : 0.029s, 146.60MB/s
dedup_time : 0.002s, 2174.00MB/s
rewrite_time : 0.000s, 100054.39MB/s
filter_time : 0.003s, 1278.94MB/s
write_time : 0.000s, 76827.48MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 2 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 23 records.
CMA: update 24 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 15
backup path: /hadoop34
number of files: 1
number of chunks: 1024 (4655 bytes on average)
number of unique chunks: 489
total size(B): 4767599
stored data size(B): 2630366
deduplication ratio: 0.4483, 1.8125
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.081s, 56.33MB/s
chunk_time : 0.016s, 278.05MB/s
hash_time : 0.016s, 284.94MB/s
dedup_time : 0.001s, 4501.72MB/s
rewrite_time : 0.000s, 108255.64MB/s
filter_time : 0.004s, 1087.74MB/s
write_time : 0.000s, 45017.20MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 1 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 0 of them are inherited
CMA: read 24 records.
CMA: update 25 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 16
backup path: /hadoop40
number of files: 1
number of chunks: 1024 (4755 bytes on average)
number of unique chunks: 277
total size(B): 4869435
stored data size(B): 1439893
deduplication ratio: 0.7043, 3.3818
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.066s, 70.49MB/s
chunk_time : 0.031s, 150.96MB/s
hash_time : 0.031s, 148.42MB/s
dedup_time : 0.001s, 4648.50MB/s
rewrite_time : 0.000s, 136583.97MB/s
filter_time : 0.002s, 2518.36MB/s
write_time : 0.000s, 91055.98MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 3 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 1 of them are inherited
CMA: read 25 records.
CMA: update 26 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 17
backup path: /hadoop41
number of files: 1
number of chunks: 1024 (4625 bytes on average)
number of unique chunks: 784
total size(B): 4736279
stored data size(B): 3998715
deduplication ratio: 0.1557, 1.1845
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.060s, 74.70MB/s
chunk_time : 0.016s, 286.73MB/s
hash_time : 0.015s, 291.92MB/s
dedup_time : 0.001s, 4241.19MB/s
rewrite_time : 0.000s, 92180.97MB/s
filter_time : 0.005s, 978.52MB/s
write_time : 0.000s, 88566.03MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 6 sparse containers, and 0 of them are inherited
CMA: read 26 records.
CMA: update 27 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 18
backup path: /hadoop43
number of files: 1
number of chunks: 1024 (4508 bytes on average)
number of unique chunks: 717
total size(B): 4617093
stored data size(B): 3637026
deduplication ratio: 0.2123, 1.2695
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.096s, 46.08MB/s
chunk_time : 0.013s, 334.44MB/s
hash_time : 0.013s, 349.85MB/s
dedup_time : 0.001s, 3053.54MB/s
rewrite_time : 0.000s, 88064.06MB/s
filter_time : 0.005s, 887.92MB/s
write_time : 0.000s, 55736.75MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 6 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 1 of them are inherited
CMA: read 27 records.
CMA: update 28 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 19
backup path: /hadoop44
number of files: 1
number of chunks: 1024 (4671 bytes on average)
number of unique chunks: 537
total size(B): 4783697
stored data size(B): 2709866
deduplication ratio: 0.4335, 1.7653
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.083s, 55.29MB/s
chunk_time : 0.018s, 258.17MB/s
hash_time : 0.014s, 329.06MB/s
dedup_time : 0.002s, 2275.36MB/s
rewrite_time : 0.000s, 123299.70MB/s
filter_time : 0.003s, 1559.69MB/s
write_time : 0.000s, 64254.77MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 3
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 459 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 28 records.
CMA: update 29 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 20
backup path: /hadoop49
number of files: 1
number of chunks: 459 (6720 bytes on average)
number of unique chunks: 459
total size(B): 3084926
stored data size(B): 3084926
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.050s, 59.43MB/s
chunk_time : 0.020s, 145.88MB/s
hash_time : 0.013s, 231.58MB/s
dedup_time : 0.000s, 12735.99MB/s
rewrite_time : 0.000s, 173059.69MB/s
filter_time : 0.003s, 1002.05MB/s
write_time : 0.000s, 52535.98MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 0 of them are inherited
CMA: read 29 records.
CMA: update 30 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 21
backup path: /hadoop50
number of files: 1
number of chunks: 1024 (4818 bytes on average)
number of unique chunks: 260
total size(B): 4934077
stored data size(B): 1379754
deduplication ratio: 0.7204, 3.5761
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.062s, 75.78MB/s
chunk_time : 0.025s, 184.76MB/s
hash_time : 0.014s, 348.38MB/s
dedup_time : 0.001s, 4489.98MB/s
rewrite_time : 0.000s, 156850.08MB/s
filter_time : 0.002s, 2617.08MB/s
write_time : 0.000s, 61110.42MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 3 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 1 of them are inherited
CMA: read 30 records.
CMA: update 31 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 22
backup path: /hadoop51
number of files: 1
number of chunks: 1024 (4575 bytes on average)
number of unique chunks: 607
total size(B): 4685003
stored data size(B): 3213604
deduplication ratio: 0.3141, 1.4579
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.065s, 68.42MB/s
chunk_time : 0.022s, 205.04MB/s
hash_time : 0.026s, 173.18MB/s
dedup_time : 0.001s, 3312.06MB/s
rewrite_time : 0.000s, 148932.23MB/s
filter_time : 0.004s, 1172.39MB/s
write_time : 0.000s, 51355.94MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 3 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 8 sparse containers, and 0 of them are inherited
CMA: read 31 records.
CMA: update 32 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 23
backup path: /hadoop53
number of files: 1
number of chunks: 1024 (4649 bytes on average)
number of unique chunks: 761
total size(B): 4761022
stored data size(B): 3965019
deduplication ratio: 0.1672, 1.2008
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.095s, 47.86MB/s
chunk_time : 0.027s, 169.19MB/s
hash_time : 0.019s, 234.66MB/s
dedup_time : 0.002s, 2443.74MB/s
rewrite_time : 0.000s, 85669.14MB/s
filter_time : 0.005s, 1005.64MB/s
write_time : 0.000s, 35197.40MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 8 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 3 of them are inherited
CMA: read 32 records.
CMA: update 33 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 24
backup path: /hadoop54
number of files: 1
number of chunks: 1024 (4589 bytes on average)
number of unique chunks: 516
total size(B): 4699341
stored data size(B): 2525651
deduplication ratio: 0.4626, 1.8606
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.083s, 54.05MB/s
chunk_time : 0.027s, 165.37MB/s
hash_time : 0.016s, 287.56MB/s
dedup_time : 0.003s, 1792.66MB/s
rewrite_time : 0.000s, 106705.73MB/s
filter_time : 0.003s, 1612.68MB/s
write_time : 0.000s, 75960.01MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 5 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 2 sparse containers, and 1 of them are inherited
CMA: read 33 records.
CMA: update 34 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 25
backup path: /hadoop55
number of files: 1
number of chunks: 1024 (4615 bytes on average)
number of unique chunks: 594
total size(B): 4726228
stored data size(B): 3070340
deduplication ratio: 0.3504, 1.5393
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.048s, 94.13MB/s
chunk_time : 0.027s, 166.66MB/s
hash_time : 0.022s, 204.90MB/s
dedup_time : 0.001s, 4300.84MB/s
rewrite_time : 0.000s, 104820.52MB/s
filter_time : 0.003s, 1465.31MB/s
write_time : 0.000s, 93901.71MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 2 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 0 of them are inherited
CMA: read 34 records.
CMA: update 35 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 26
backup path: /hadoop60
number of files: 1
number of chunks: 1024 (4815 bytes on average)
number of unique chunks: 203
total size(B): 4930976
stored data size(B): 1096079
deduplication ratio: 0.7777, 4.4987
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.078s, 60.02MB/s
chunk_time : 0.025s, 191.44MB/s
hash_time : 0.016s, 288.57MB/s
dedup_time : 0.001s, 4255.70MB/s
rewrite_time : 0.000s, 111965.36MB/s
filter_time : 0.002s, 2173.08MB/s
write_time : 0.000s, 18086.71MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 3 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 1 of them are inherited
CMA: read 35 records.
CMA: update 36 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 27
backup path: /hadoop61
number of files: 1
number of chunks: 1024 (4626 bytes on average)
number of unique chunks: 570
total size(B): 4737349
stored data size(B): 3164019
deduplication ratio: 0.3321, 1.4973
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.106s, 42.76MB/s
chunk_time : 0.013s, 339.84MB/s
hash_time : 0.024s, 184.44MB/s
dedup_time : 0.002s, 2956.73MB/s
rewrite_time : 0.000s, 27216.19MB/s
filter_time : 0.003s, 1475.95MB/s
write_time : 0.000s, 74063.74MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 7 sparse containers, and 0 of them are inherited
CMA: read 36 records.
CMA: update 37 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 28
backup path: /hadoop63
number of files: 1
number of chunks: 1024 (4672 bytes on average)
number of unique chunks: 586
total size(B): 4784751
stored data size(B): 3353707
deduplication ratio: 0.2991, 1.4267
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.102s, 44.67MB/s
chunk_time : 0.040s, 114.89MB/s
hash_time : 0.013s, 358.99MB/s
dedup_time : 0.002s, 2469.21MB/s
rewrite_time : 0.000s, 101402.09MB/s
filter_time : 0.004s, 1075.44MB/s
write_time : 0.000s, 19753.65MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 7 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 3 of them are inherited
CMA: read 37 records.
CMA: update 38 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 29
backup path: /hadoop64
number of files: 1
number of chunks: 1024 (4601 bytes on average)
number of unique chunks: 425
total size(B): 4711842
stored data size(B): 2226555
deduplication ratio: 0.5275, 2.1162
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.063s, 71.15MB/s
chunk_time : 0.024s, 189.18MB/s
hash_time : 0.012s, 390.68MB/s
dedup_time : 0.002s, 1801.03MB/s
rewrite_time : 0.000s, 102126.42MB/s
filter_time : 0.003s, 1719.69MB/s
write_time : 0.000s, 86414.67MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 5 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 1 of them are inherited
CMA: read 38 records.
CMA: update 39 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 30
backup path: /hadoop65
number of files: 1
number of chunks: 1024 (4607 bytes on average)
number of unique chunks: 559
total size(B): 4717890
stored data size(B): 2955474
deduplication ratio: 0.3736, 1.5963
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.060s, 74.68MB/s
chunk_time : 0.013s, 346.88MB/s
hash_time : 0.016s, 274.35MB/s
dedup_time : 0.002s, 2376.83MB/s
rewrite_time : 0.000s, 67154.19MB/s
filter_time : 0.008s, 537.30MB/s
write_time : 0.000s, 33829.55MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
==== backup begin ====
Read 3 inherited sparse containers
append thread start
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 0 of them are inherited
CMA: read 39 records.
CMA: update 40 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 31
backup path: /hadoop70
number of files: 1
number of chunks: 1024 (4726 bytes on average)
number of unique chunks: 274
total size(B): 4839699
stored data size(B): 1316282
deduplication ratio: 0.7280, 3.6768
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.128s, 36.19MB/s
chunk_time : 0.025s, 185.35MB/s
hash_time : 0.014s, 325.88MB/s
dedup_time : 0.001s, 4547.29MB/s
rewrite_time : 0.000s, 135749.90MB/s
filter_time : 0.002s, 2802.37MB/s
write_time : 0.000s, 55608.39MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 3 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 1 of them are inherited
CMA: read 40 records.
CMA: update 41 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 32
backup path: /hadoop71
number of files: 1
number of chunks: 1024 (4501 bytes on average)
number of unique chunks: 628
total size(B): 4609728
stored data size(B): 3192351
deduplication ratio: 0.3075, 1.4440
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.052s, 84.22MB/s
chunk_time : 0.021s, 204.82MB/s
hash_time : 0.014s, 314.60MB/s
dedup_time : 0.002s, 1950.39MB/s
rewrite_time : 0.000s, 81410.73MB/s
filter_time : 0.004s, 1144.84MB/s
write_time : 0.000s, 64649.69MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 1 of them are inherited
CMA: read 41 records.
CMA: update 43 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 33
backup path: /hadoop72
number of files: 1
number of chunks: 1024 (4770 bytes on average)
number of unique chunks: 990
total size(B): 4884926
stored data size(B): 4839490
deduplication ratio: 0.0093, 1.0094
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.055s, 84.23MB/s
chunk_time : 0.016s, 292.32MB/s
hash_time : 0.013s, 352.50MB/s
dedup_time : 0.003s, 1850.87MB/s
rewrite_time : 0.001s, 7465.75MB/s
filter_time : 0.018s, 257.21MB/s
write_time : 0.000s, 10758.96MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 5 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 2 of them are inherited
CMA: read 43 records.
CMA: update 44 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 34
backup path: /hadoop73
number of files: 1
number of chunks: 1024 (4609 bytes on average)
number of unique chunks: 702
total size(B): 4719713
stored data size(B): 3615842
deduplication ratio: 0.2339, 1.3053
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.066s, 68.19MB/s
chunk_time : 0.045s, 99.09MB/s
hash_time : 0.028s, 161.09MB/s
dedup_time : 0.004s, 1159.47MB/s
rewrite_time : 0.000s, 10047.03MB/s
filter_time : 0.016s, 283.46MB/s
write_time : 0.002s, 1973.29MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 5 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 7 sparse containers, and 1 of them are inherited
CMA: read 44 records.
CMA: update 45 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 35
backup path: /hadoop74
number of files: 1
number of chunks: 1024 (4580 bytes on average)
number of unique chunks: 513
total size(B): 4690136
stored data size(B): 2511535
deduplication ratio: 0.4645, 1.8674
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.020s, 225.75MB/s
chunk_time : 0.014s, 328.45MB/s
hash_time : 0.015s, 294.27MB/s
dedup_time : 0.002s, 2615.71MB/s
rewrite_time : 0.000s, 91282.90MB/s
filter_time : 0.004s, 1209.21MB/s
write_time : 0.000s, 22253.05MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 7 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 2 of them are inherited
CMA: read 45 records.
CMA: update 46 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 36
backup path: /hadoop75
number of files: 1
number of chunks: 1024 (4564 bytes on average)
number of unique chunks: 641
total size(B): 4673960
stored data size(B): 3313945
deduplication ratio: 0.2910, 1.4104
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.102s, 43.76MB/s
chunk_time : 0.033s, 136.80MB/s
hash_time : 0.025s, 175.78MB/s
dedup_time : 0.002s, 2547.11MB/s
rewrite_time : 0.000s, 82545.10MB/s
filter_time : 0.003s, 1478.42MB/s
write_time : 0.000s, 76852.34MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 1
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 34 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 46 records.
CMA: update 47 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 37
backup path: /hadoop710
number of files: 1
number of chunks: 34 (5366 bytes on average)
number of unique chunks: 34
total size(B): 182459
stored data size(B): 182459
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.002s, 91.20MB/s
chunk_time : 0.001s, 341.19MB/s
hash_time : 0.001s, 346.63MB/s
dedup_time : 0.000s, 6214.52MB/s
rewrite_time : 0.000s, infMB/s
filter_time : 0.000s, 630.46MB/s
write_time : 0.000s, 2718.85MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
==== backup begin ====
pkt size: 5
Read 0 inherited sparse containers
append thread start
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 0 of them are inherited
CMA: read 47 records.
CMA: update 48 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 38
backup path: /hadoop80
number of files: 1
number of chunks: 1024 (4791 bytes on average)
number of unique chunks: 241
total size(B): 4906301
stored data size(B): 1217946
deduplication ratio: 0.7518, 4.0283
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.082s, 57.06MB/s
chunk_time : 0.027s, 175.99MB/s
hash_time : 0.014s, 342.61MB/s
dedup_time : 0.001s, 3968.63MB/s
rewrite_time : 0.000s, 111405.08MB/s
filter_time : 0.002s, 3005.15MB/s
write_time : 0.000s, 95490.07MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
==== backup begin ====
Read 3 inherited sparse containers
append thread start
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 6 sparse containers, and 1 of them are inherited
CMA: read 48 records.
CMA: update 49 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 39
backup path: /hadoop81
number of files: 1
number of chunks: 1024 (4577 bytes on average)
number of unique chunks: 614
total size(B): 4687220
stored data size(B): 3190759
deduplication ratio: 0.3193, 1.4690
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.026s, 174.98MB/s
chunk_time : 0.015s, 293.06MB/s
hash_time : 0.015s, 299.80MB/s
dedup_time : 0.001s, 3063.80MB/s
rewrite_time : 0.000s, 99335.14MB/s
filter_time : 0.004s, 995.56MB/s
write_time : 0.000s, 75764.09MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 6 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 6 sparse containers, and 0 of them are inherited
CMA: read 49 records.
CMA: update 50 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 40
backup path: /hadoop83
number of files: 1
number of chunks: 1024 (4624 bytes on average)
number of unique chunks: 694
total size(B): 4735875
stored data size(B): 3541316
deduplication ratio: 0.2522, 1.3373
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.121s, 37.32MB/s
chunk_time : 0.024s, 184.60MB/s
hash_time : 0.015s, 308.46MB/s
dedup_time : 0.002s, 2822.80MB/s
rewrite_time : 0.000s, 102647.33MB/s
filter_time : 0.005s, 970.24MB/s
write_time : 0.000s, 80651.47MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 6 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 8 sparse containers, and 2 of them are inherited
CMA: read 50 records.
CMA: update 51 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 41
backup path: /hadoop84
number of files: 1
number of chunks: 1024 (4723 bytes on average)
number of unique chunks: 549
total size(B): 4837339
stored data size(B): 2807777
deduplication ratio: 0.4196, 1.7228
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.093s, 49.67MB/s
chunk_time : 0.026s, 174.20MB/s
hash_time : 0.017s, 266.40MB/s
dedup_time : 0.002s, 1974.00MB/s
rewrite_time : 0.000s, 121401.21MB/s
filter_time : 0.004s, 1175.95MB/s
write_time : 0.000s, 83877.20MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 8 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 2 of them are inherited
CMA: read 51 records.
CMA: update 52 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 42
backup path: /hadoop85
number of files: 1
number of chunks: 1024 (4608 bytes on average)
number of unique chunks: 691
total size(B): 4719376
stored data size(B): 3538133
deduplication ratio: 0.2503, 1.3339
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.046s, 97.29MB/s
chunk_time : 0.023s, 194.36MB/s
hash_time : 0.016s, 280.53MB/s
dedup_time : 0.002s, 2793.76MB/s
rewrite_time : 0.000s, 93765.58MB/s
filter_time : 0.008s, 544.88MB/s
write_time : 0.000s, 64296.40MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 5
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 52 records.
CMA: update 53 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 43
backup path: /hadoop86
number of files: 1
number of chunks: 1024 (4310 bytes on average)
number of unique chunks: 837
total size(B): 4413592
stored data size(B): 3610485
deduplication ratio: 0.1820, 1.2224
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.051s, 82.49MB/s
chunk_time : 0.033s, 126.29MB/s
hash_time : 0.014s, 291.41MB/s
dedup_time : 0.001s, 4745.35MB/s
rewrite_time : 0.000s, 65767.65MB/s
filter_time : 0.015s, 287.18MB/s
write_time : 0.000s, 12235.84MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 53 records.
CMA: update 55 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 44
backup path: /hadoop89
number of files: 1
number of chunks: 1024 (4822 bytes on average)
number of unique chunks: 1024
total size(B): 4938034
stored data size(B): 4938034
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.067s, 69.83MB/s
chunk_time : 0.045s, 103.61MB/s
hash_time : 0.012s, 391.20MB/s
dedup_time : 0.001s, 8737.06MB/s
rewrite_time : 0.000s, 114860.40MB/s
filter_time : 0.007s, 711.37MB/s
write_time : 0.000s, 40250.22MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 3
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 373 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 55 records.
CMA: update 56 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 45
backup path: /hadoop810
number of files: 1
number of chunks: 373 (7532 bytes on average)
number of unique chunks: 373
total size(B): 2809738
stored data size(B): 2809738
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.066s, 40.76MB/s
chunk_time : 0.010s, 271.84MB/s
hash_time : 0.009s, 306.10MB/s
dedup_time : 0.000s, 12463.14MB/s
rewrite_time : 0.000s, 167473.44MB/s
filter_time : 0.003s, 785.34MB/s
write_time : 0.000s, 47010.09MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 0 of them are inherited
CMA: read 56 records.
CMA: update 57 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 46
backup path: /hadoop90
number of files: 1
number of chunks: 1024 (4806 bytes on average)
number of unique chunks: 214
total size(B): 4922002
stored data size(B): 1159607
deduplication ratio: 0.7644, 4.2445
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.087s, 54.17MB/s
chunk_time : 0.025s, 188.42MB/s
hash_time : 0.045s, 103.35MB/s
dedup_time : 0.001s, 3879.33MB/s
rewrite_time : 0.000s, 146687.09MB/s
filter_time : 0.002s, 3078.02MB/s
write_time : 0.000s, 57243.74MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 6 sparse containers, and 1 of them are inherited
CMA: read 57 records.
CMA: update 58 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 47
backup path: /hadoop91
number of files: 1
number of chunks: 1024 (4503 bytes on average)
number of unique chunks: 596
total size(B): 4611502
stored data size(B): 3090297
deduplication ratio: 0.3299, 1.4923
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.055s, 80.38MB/s
chunk_time : 0.013s, 329.06MB/s
hash_time : 0.014s, 315.35MB/s
dedup_time : 0.002s, 2157.93MB/s
rewrite_time : 0.000s, 59430.69MB/s
filter_time : 0.005s, 835.46MB/s
write_time : 0.000s, 81442.06MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 6 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 9 sparse containers, and 2 of them are inherited
CMA: read 58 records.
CMA: update 60 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 48
backup path: /hadoop92
number of files: 1
number of chunks: 1024 (4876 bytes on average)
number of unique chunks: 854
total size(B): 4993882
stored data size(B): 4512121
deduplication ratio: 0.0965, 1.1068
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.108s, 44.24MB/s
chunk_time : 0.037s, 129.54MB/s
hash_time : 0.039s, 121.96MB/s
dedup_time : 0.003s, 1381.25MB/s
rewrite_time : 0.000s, 119063.43MB/s
filter_time : 0.007s, 697.91MB/s
write_time : 0.000s, 41776.64MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 9 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 6 sparse containers, and 3 of them are inherited
CMA: read 60 records.
CMA: update 61 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 49
backup path: /hadoop93
number of files: 1
number of chunks: 1024 (4736 bytes on average)
number of unique chunks: 601
total size(B): 4850361
stored data size(B): 3450885
deduplication ratio: 0.2885, 1.4055
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.072s, 64.11MB/s
chunk_time : 0.044s, 104.32MB/s
hash_time : 0.021s, 220.04MB/s
dedup_time : 0.002s, 2285.41MB/s
rewrite_time : 0.000s, 94401.32MB/s
filter_time : 0.003s, 1330.74MB/s
write_time : 0.000s, 24092.00MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 6 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 9 sparse containers, and 2 of them are inherited
CMA: read 61 records.
CMA: update 62 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 50
backup path: /hadoop94
number of files: 1
number of chunks: 1024 (4774 bytes on average)
number of unique chunks: 488
total size(B): 4888894
stored data size(B): 2720020
deduplication ratio: 0.4436, 1.7974
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.051s, 91.63MB/s
chunk_time : 0.045s, 103.59MB/s
hash_time : 0.024s, 191.48MB/s
dedup_time : 0.002s, 1987.39MB/s
rewrite_time : 0.000s, 105963.92MB/s
filter_time : 0.003s, 1546.41MB/s
write_time : 0.000s, 76432.99MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 9 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 5 sparse containers, and 2 of them are inherited
CMA: read 62 records.
CMA: update 63 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 51
backup path: /hadoop95
number of files: 1
number of chunks: 1024 (4599 bytes on average)
number of unique chunks: 638
total size(B): 4710359
stored data size(B): 3377391
deduplication ratio: 0.2830, 1.3947
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.125s, 36.03MB/s
chunk_time : 0.018s, 248.71MB/s
hash_time : 0.015s, 302.99MB/s
dedup_time : 0.002s, 2116.94MB/s
rewrite_time : 0.000s, 74869.14MB/s
filter_time : 0.009s, 498.02MB/s
write_time : 0.000s, 23642.89MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 5 inherited sparse containers
pkt size: 5
[debug] container meta not found
write container buffer1
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 63 records.
CMA: update 65 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 52
backup path: /hadoop99
number of files: 1
number of chunks: 1024 (4895 bytes on average)
number of unique chunks: 739
total size(B): 5013110
stored data size(B): 4261659
deduplication ratio: 0.1499, 1.1763
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.061s, 78.32MB/s
chunk_time : 0.013s, 372.57MB/s
hash_time : 0.024s, 200.63MB/s
dedup_time : 0.001s, 6999.82MB/s
rewrite_time : 0.000s, 66401.03MB/s
filter_time : 0.019s, 249.19MB/s
write_time : 0.000s, 33906.91MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 1 inherited sparse containers
pkt size: 3
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 354 chunks on average
rewrite phase stops successfully!
Record 0 sparse containers, and 0 of them are inherited
CMA: read 65 records.
CMA: update 66 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 53
backup path: /hadoop910
number of files: 1
number of chunks: 354 (7263 bytes on average)
number of unique chunks: 354
total size(B): 2571273
stored data size(B): 2571273
deduplication ratio: 0.0000, 1.0000
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.028s, 88.78MB/s
chunk_time : 0.014s, 170.80MB/s
hash_time : 0.007s, 332.95MB/s
dedup_time : 0.000s, 12199.79MB/s
rewrite_time : 0.000s, 175154.07MB/s
filter_time : 0.002s, 1180.62MB/s
write_time : 0.000s, 52173.55MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
Init index module successfully
==== backup begin ====
Read 0 inherited sparse containers
append thread start
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 3 sparse containers, and 0 of them are inherited
CMA: read 66 records.
CMA: update 67 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 54
backup path: /hadoop100
number of files: 1
number of chunks: 1024 (4684 bytes on average)
number of unique chunks: 211
total size(B): 4796723
stored data size(B): 1019940
deduplication ratio: 0.7874, 4.7029
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.061s, 75.06MB/s
chunk_time : 0.019s, 235.79MB/s
hash_time : 0.021s, 215.87MB/s
dedup_time : 0.001s, 3120.40MB/s
rewrite_time : 0.000s, 147564.89MB/s
filter_time : 0.001s, 3587.85MB/s
write_time : 0.000s, 93357.38MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 3 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 10 sparse containers, and 3 of them are inherited
CMA: read 67 records.
CMA: update 68 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 55
backup path: /hadoop101
number of files: 1
number of chunks: 1024 (4596 bytes on average)
number of unique chunks: 569
total size(B): 4707062
stored data size(B): 3144695
deduplication ratio: 0.3319, 1.4968
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.061s, 73.84MB/s
chunk_time : 0.039s, 116.36MB/s
hash_time : 0.030s, 148.44MB/s
dedup_time : 0.002s, 2278.68MB/s
rewrite_time : 0.000s, 115102.67MB/s
filter_time : 0.004s, 1004.25MB/s
write_time : 0.000s, 73590.23MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 10 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 8 sparse containers, and 0 of them are inherited
CMA: read 68 records.
CMA: update 69 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 56
backup path: /hadoop103
number of files: 1
number of chunks: 1024 (4680 bytes on average)
number of unique chunks: 570
total size(B): 4793267
stored data size(B): 3375880
deduplication ratio: 0.2957, 1.4199
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.052s, 87.75MB/s
chunk_time : 0.039s, 116.47MB/s
hash_time : 0.014s, 331.95MB/s
dedup_time : 0.002s, 1971.20MB/s
rewrite_time : 0.000s, 51361.97MB/s
filter_time : 0.007s, 649.23MB/s
write_time : 0.001s, 8251.29MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 8 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 8 sparse containers, and 2 of them are inherited
CMA: read 69 records.
CMA: update 70 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 57
backup path: /hadoop104
number of files: 1
number of chunks: 1024 (4736 bytes on average)
number of unique chunks: 459
total size(B): 4849992
stored data size(B): 2640976
deduplication ratio: 0.4555, 1.8364
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.110s, 42.22MB/s
chunk_time : 0.025s, 185.65MB/s
hash_time : 0.023s, 201.21MB/s
dedup_time : 0.004s, 1092.16MB/s
rewrite_time : 0.000s, 118597.76MB/s
filter_time : 0.003s, 1691.77MB/s
write_time : 0.000s, 112812.51MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 8 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 6 sparse containers, and 2 of them are inherited
CMA: read 70 records.
CMA: update 71 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 58
backup path: /hadoop105
number of files: 1
number of chunks: 1024 (4561 bytes on average)
number of unique chunks: 626
total size(B): 4671139
stored data size(B): 3309736
deduplication ratio: 0.2914, 1.4113
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.063s, 71.09MB/s
chunk_time : 0.023s, 197.46MB/s
hash_time : 0.018s, 245.62MB/s
dedup_time : 0.002s, 2176.23MB/s
rewrite_time : 0.000s, 75504.16MB/s
filter_time : 0.005s, 839.41MB/s
write_time : 0.000s, 74245.75MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
pkt size: 5
Read 6 inherited sparse containers
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 4 sparse containers, and 2 of them are inherited
CMA: read 71 records.
CMA: update 72 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 59
backup path: /hadoop106
number of files: 1
number of chunks: 1024 (4401 bytes on average)
number of unique chunks: 661
total size(B): 4507230
stored data size(B): 3070257
deduplication ratio: 0.3188, 1.4680
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.039s, 110.76MB/s
chunk_time : 0.017s, 257.51MB/s
hash_time : 0.031s, 137.02MB/s
dedup_time : 0.002s, 2800.28MB/s
rewrite_time : 0.000s, 82662.11MB/s
filter_time : 0.004s, 1030.30MB/s
write_time : 0.000s, 74110.85MB/s
1
2
destor_server_process
destor_server_process: receive a request!
type: 0 
Init recipe store successfully
[debug] destor init_container_store, in read mode.
Init container store successfully
append thread start
Init index module successfully
==== backup begin ====
Read 4 inherited sparse containers
pkt size: 5
[debug] container meta not found
[debug] container meta not found
write container buffer2
push container buffer
[debug] destor in append thread, get one chunk from buffer.
write_container start
append thread end
append thread start
read phase stops successfully!
chunk phase stops successfully!
hash phase stops successfully!
dedup phase stops successfully: 1 segments of 1024 chunks on average
rewrite phase stops successfully!
Record 1 sparse containers, and 0 of them are inherited
CMA: read 72 records.
CMA: update 73 records.
filter phase stops successfully!
flushing hash table!
flushing hash table successfully!
[debug] destor in append thread, break.
append phase stops successfully!
==== backup end ====
job id: 60
backup path: /hadoop109
number of files: 1
number of chunks: 1024 (4461 bytes on average)
number of unique chunks: 738
total size(B): 4568805
stored data size(B): 3811977
deduplication ratio: 0.1657, 1.1985
total time(s): 0.000
throughput(MB/s): inf
number of zero chunks: 0
size of zero chunks: 0
number of rewritten chunks: 0
size of rewritten chunks: 0
rewritten rate in size: 0.000
read_time : 0.026s, 168.02MB/s
chunk_time : 0.012s, 376.14MB/s
hash_time : 0.015s, 298.91MB/s
dedup_time : 0.001s, 4309.74MB/s
rewrite_time : 0.000s, 87143.04MB/s
filter_time : 0.005s, 840.82MB/s
write_time : 0.000s, 67033.11MB/s
1
2
